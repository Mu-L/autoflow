{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from app.core.db import Scoped_Session\n",
    "\n",
    "session = Scoped_Session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zhaiyl/miniconda3/envs/tidbai/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import dspy\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "turbo = dspy.OpenAI(model='gpt-4o', api_key=os.getenv(\"OPENAI_API_KEY\"), max_tokens=4096)\n",
    "dspy.settings.configure(lm=turbo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "from sqlalchemy.exc import SAWarning\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", category=SAWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from app.rag.knowledge_graph.graph_store import TiDBGraphStore\n",
    "from app.rag.knowledge_graph import KnowledgeGraphIndex\n",
    "from llama_index.embeddings.openai import OpenAIEmbedding, OpenAIEmbeddingModelType\n",
    "\n",
    "_embed_model = OpenAIEmbedding(\n",
    "    model=OpenAIEmbeddingModelType.TEXT_EMBED_3_SMALL\n",
    ")\n",
    "\n",
    "graph_store = TiDBGraphStore(\n",
    "    dspy_lm=turbo,\n",
    "    session=session,\n",
    "    embed_model=_embed_model,\n",
    ")\n",
    "graph_index =  KnowledgeGraphIndex = KnowledgeGraphIndex.from_existing(\n",
    "    dspy_lm=turbo,\n",
    "    kg_store=graph_store,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrieve_knowledge_graph(query):\n",
    "    return graph_index.graph_semantic_search(\n",
    "        query,\n",
    "        include_meta=True,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from app.rag.vector_store.tidb_vector_store import TiDBVectorStore\n",
    "from llama_index.core import VectorStoreIndex\n",
    "\n",
    "vector_store = TiDBVectorStore(session=session)\n",
    "vector_index = VectorStoreIndex.from_vector_store(\n",
    "    vector_store,\n",
    "    embed_model=_embed_model\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrieve_knowledge_embedded_chunks(query, top_k=5):\n",
    "    retriver = vector_index.as_retriever(\n",
    "        similarity_top_k=5\n",
    "    )\n",
    "\n",
    "    nodes = retriver.retrieve(query)\n",
    "    return [node.text for node in nodes]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['## BR command-line description\\n\\nA `br` command consists of sub-commands, options, and parameters.\\n\\n* Sub-command: the characters without `-` or `--`.\\n* Option: the characters that start with `-` or `--`.\\n* Parameter: the characters that immediately follow behind and are passed to the sub-command or the option.\\n\\nThis is a complete `br` command:\\n\\n{{< copyable \"shell-regular\" >}}\\n\\n```shell\\n`br backup full --pd \"${PDIP}:2379\" -s \"s3://backup-data/2022-01-30/\"`\\n```\\n\\nExplanations for the above command are as follows:\\n\\n* `backup`: the sub-command of `br`.\\n* `full`: the sub-command of `backup`.\\n* `-s` (or `--storage`): the option that specifies the path where the backup files are stored.\\n* `\"s3://backup-data/2022-01-30/\"`: the parameter of `-s`, indicating that backup data is stored to the `2022-01-30/` directory in the `backup-data` bucket of Amazon S3.\\n* `--pd`: the option that specifies the Placement Driver (PD) service address.\\n* `\"${PDIP}:2379\"`: the parameter of `--pd`.\\n\\n### Sub-commands\\n\\nA `br` command consists of multiple layers of sub-commands. Currently, BR has the following sub-commands:\\n\\n* `br backup`: used to back up the data of the TiDB cluster.\\n* `br restore`: used to restore the data of the TiDB cluster.\\n\\nEach of the above sub-commands might still include the following sub-commands to specify the scope of an operation:\\n\\n* `full`: used to back up or restore all the cluster data.\\n* `db`: used to back up or restore the specified database of the cluster.\\n* `table`: used to back up or restore a single table in the specified database of the cluster.\\n\\n### Common options\\n\\n* `--pd`: used for connection, specifying the PD server address. For example, `\"${PDIP}:2379\"`.\\n* `-h` (or `--help`): used to get help on all sub-commands. For example, `br backup --help`.\\n* `-V` (or `--version`): used to check the version of BR.\\n* `--ca`: specifies the path to the trusted CA certificate in the PEM format.\\n* `--cert`: specifies the path to the SSL certificate in the PEM format.\\n* `--key`: specifies the path to the SSL certificate key in the PEM format.\\n* `--status-addr`: specifies the listening address through which BR provides statistics to Prometheus.',\n",
       " '## BR command-line description\\n\\nA `br` command consists of sub-commands, options, and parameters.\\n\\n* Sub-command: the characters without `-` or `--`.\\n* Option: the characters that start with `-` or `--`.\\n* Parameter: the characters that immediately follow behind and are passed to the sub-command or the option.\\n\\nThis is a complete `br` command:\\n\\n{{< copyable \"shell-regular\" >}}\\n\\n```shell\\nbr backup full --pd \"${PDIP}:2379\" -s \"local:///tmp/backup\"\\n```\\n\\nExplanations for the above command are as follows:\\n\\n* `backup`: the sub-command of `br`.\\n* `full`: the sub-command of `backup`.\\n* `-s` (or `--storage`): the option that specifies the path where the backup files are stored.\\n* `\"local:///tmp/backup\"`: the parameter of `-s`. `/tmp/backup` is the path in the local disk where the backed up files of each TiKV node are stored.\\n* `--pd`: the option that specifies the Placement Driver (PD) service address.\\n* `\"${PDIP}:2379\"`: the parameter of `--pd`.\\n\\n> **Note:**\\n>\\n> - When the `local` storage is used, the backup data are scattered in the local file system of each node.\\n>\\n> - It is **not recommended** to back up to a local disk in the production environment because you **have to** manually aggregate these data to complete the data restoration. For more information, see [Restore Cluster Data](#use-br-command-line-to-restore-cluster-data).\\n>\\n> - Aggregating these backup data might cause redundancy and bring troubles to operation and maintenance. Even worse, if restoring data without aggregating these data, you can receive a rather confusing error message `SST file not found`.\\n>\\n> - It is recommended to mount the NFS disk on each node, or back up to the `S3` object storage.\\n\\n### Sub-commands\\n\\nA `br` command consists of multiple layers of sub-commands. Currently, BR has the following three sub-commands:\\n\\n* `br backup`: used to back up the data of the TiDB cluster.\\n* `br restore`: used to restore the data of the TiDB cluster.\\n\\nEach of the above three sub-commands might still include the following three sub-commands to specify the scope of an operation:\\n\\n* `full`: used to back up or restore all the cluster data.\\n* `db`: used to back up or restore the specified database of the cluster.\\n* `table`: used to back up or restore a single table in the specified database of the cluster.\\n\\n### Common options\\n\\n* `--pd`: used for connection, specifying the PD server address. For example, `\"${PDIP}:2379\"`.\\n* `-h` (or `--help`): used to get help on all sub-commands. For example, `br backup --help`.\\n* `-V` (or `--version`): used to check the version of BR.\\n* `--ca`: specifies the path to the trusted CA certificate in the PEM format.\\n* `--cert`: specifies the path to the SSL certificate in the PEM format.\\n* `--key`: specifies the path to the SSL certificate key in the PEM format.\\n* `--status-addr`: specifies the listening address through which BR provides statistics to Prometheus.',\n",
       " '---\\ntitle: br Command-line Manual\\nsummary: Learn about the description, options, and usage of the br command-line tool.\\n---\\n\\n# br Command-line Manual\\n\\nThis document describes the definition, components, and common options of `br` commands, and how to perform snapshot backup and restore, and log backup and point-in-time recovery (PITR) using `br` commands.',\n",
       " \"---\\ntitle: BR Overview\\nsummary: Learn about the definition and functions of BR.\\naliases: ['/tidb/stable/backup-and-restore-tool/']\\n---\\n\\n# BR Overview\\n\\n[BR](https://github.com/pingcap/tidb/tree/master/br) (Backup & Restore) is a command-line tool for **distributed backup and restoration** of the TiDB cluster data. In addition to regular backup and restoration, you can also use BR for large-scale data migration as long as compatibility is ensured.\\n\\nThis document describes BR's architecture, features, and usage tips.\",\n",
       " '## BR command-line description\\n\\nA `br` command consists of sub-commands, options, and parameters.\\n\\n* Sub-command: the characters without `-` or `--`.\\n* Option: the characters that start with `-` or `--`.\\n* Parameter: the characters that immediately follow behind and are passed to the sub-command or the option.\\n\\nThis is a complete `br` command:\\n\\n{{< copyable \"shell-regular\" >}}\\n\\n```shell\\nbr backup full --pd \"${PDIP}:2379\" -s \"local:///tmp/backup\"\\n```\\n\\nExplanations for the above command are as follows:\\n\\n* `backup`: the sub-command of `br`.\\n* `full`: the sub-command of `backup`.\\n* `-s` (or `--storage`): the option that specifies the path where the backup files are stored.\\n* `\"local:///tmp/backup\"`: the parameter of `-s`. `/tmp/backup` is the path in the local disk where the backed up files of each TiKV node are stored.\\n* `--pd`: the option that specifies the Placement Driver (PD) service address.\\n* `\"${PDIP}:2379\"`: the parameter of `--pd`.\\n\\n> **Note:**\\n>\\n> - When the `local` storage is used, the backup data are scattered in the local file system of each node.\\n>\\n> - It is **not recommended** to back up to a local disk in the production environment because you **have to** manually aggregate these data to complete the data restoration. For more information, see [Restore Cluster Data](#use-br-command-line-to-restore-cluster-data).\\n>\\n> - Aggregating these backup data might cause redundancy and bring troubles to operation and maintenance. Even worse, if restoring data without aggregating these data, you can receive a rather confusing error message `SST file not found`.\\n>\\n> - It is recommended to mount the NFS disk on each node, or back up to the `S3` object storage.\\n\\n### Sub-commands\\n\\nA `br` command consists of multiple layers of sub-commands. Currently, BR has the following three sub-commands:\\n\\n* `br backup`: used to back up the data of the TiDB cluster.\\n* `br restore`: used to restore the data of the TiDB cluster.\\n\\nEach of the above three sub-commands might still include the following three sub-commands to specify the scope of an operation:\\n\\n* `full`: used to back up or restore all the cluster data.\\n* `db`: used to back up or restore the specified database of the cluster.\\n* `table`: used to back up or restore a single table in the specified database of the cluster.\\n\\n### Common options\\n\\n* `--pd`: used for connection, specifying the PD server address. For example, `\"${PDIP}:2379\"`.\\n* `-h` (or `--help`): used to get help on all sub-commands. For example, `br backup --help`.\\n* `-V` (or `--version`): used to check the version of BR.\\n* `--ca`: specifies the path to the trusted CA certificate in the PEM format.\\n* `--cert`: specifies the path to the SSL certificate in the PEM format.\\n* `--key`: specifies the path to the SSL certificate key in the PEM format.\\n* `--status-addr`: specifies the listening address through which BR provides statistics to Prometheus.']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retrieve_knowledge_embedded_chunks(\"what's br?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import enum\n",
    "import openai\n",
    "from pydantic import BaseModel, Field, field_validator\n",
    "from sqlmodel import Session\n",
    "import traceback\n",
    "from typing import Generator, Any, List\n",
    "from dataclasses import dataclass\n",
    "\n",
    "\n",
    "fc_llm = openai.OpenAI(api_key=os.getenv(\"OPENAI_API_KEY\"))\n",
    "\n",
    "\n",
    "class EventType(str, enum.Enum):\n",
    "    LLM_CONTENT_STREAMING = \"LLM_CONTENT_STREAMING\"\n",
    "    TOOL_CALL = \"TOOL_CALL\"\n",
    "    TOOL_CALL_RESPONSE = \"TOOL_CALL_RESPONSE\"\n",
    "    FINISHED = \"FINISHED\"\n",
    "    ERROR = \"ERROR\"\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class ChatEvent:\n",
    "    event_type: EventType\n",
    "    payload: str | dict | None = None\n",
    "\n",
    "    def encode(self, charset) -> bytes:\n",
    "        body = self.payload\n",
    "        body = json.dumps(body, separators=(\",\", \":\"))\n",
    "        return f\"{self.event_type.value}:{body}\\n\".encode(charset)\n",
    "\n",
    "\n",
    "class MessageRole(str, enum.Enum):\n",
    "    SYSTEM = \"system\"\n",
    "    USER = \"user\"\n",
    "    ASSISTANT = \"assistant\"\n",
    "    TOOL = \"tool\"\n",
    "\n",
    "\n",
    "class ChatMessage(BaseModel):\n",
    "    role: MessageRole\n",
    "    content: str\n",
    "    additional_kwargs: dict[str, Any] = {}\n",
    "\n",
    "\n",
    "# chat api definition\n",
    "class ChatRequest(BaseModel):\n",
    "    user_id: str\n",
    "    messages: list[ChatMessage] = []\n",
    "    metadata: dict = {}\n",
    "    stream: bool = True\n",
    "\n",
    "    @field_validator(\"messages\")\n",
    "    @classmethod\n",
    "    def check_messages(cls, messages: List[ChatMessage]) -> List[ChatMessage]:\n",
    "        if not messages:\n",
    "            raise ValueError(\"messages cannot be empty\")\n",
    "        for m in messages:\n",
    "            if m.role not in [\n",
    "                MessageRole.USER,\n",
    "                MessageRole.ASSISTANT,\n",
    "                MessageRole.TOOL,\n",
    "            ]:\n",
    "                raise ValueError(\"role must be either 'user' or 'assistant'\")\n",
    "            if len(m.content) > 8096:\n",
    "                raise ValueError(\"message content cannot exceed 8096 characters\")\n",
    "        if messages[-1].role != MessageRole.USER:\n",
    "            raise ValueError(\"last message must be from user\")\n",
    "        return messages\n",
    "\n",
    "\n",
    "class GraphKnowledge(BaseModel):\n",
    "    \"\"\"\n",
    "    Represents structured knowledge in the form of a graph, focusing on entities and the relationships between them.\n",
    "\n",
    "    This tool enables users to query and navigate structured relationships between various entities. It is designed to answer questions where understanding the relationships or attributes of specific entities is key to providing an accurate response.\n",
    "\n",
    "    Typical use cases include:\n",
    "    1. **Entity Queries**: Answering questions about the relationships or properties of specific entities.\n",
    "    2. **Relationship Navigation**: Navigating through structured relationships to retrieve specific knowledge tied to entities within the organization's domain.\n",
    "    \"\"\"\n",
    "\n",
    "    query: str = Field(\n",
    "        description=(\n",
    "            \"A query for retrieving structured relationships and attributes of specific entities.\"\n",
    "        )\n",
    "    )\n",
    "\n",
    "class VectorChunks(BaseModel):\n",
    "    \"\"\"\n",
    "    Represents detailed source data in the form of vectorized chunks, focusing on the content of original documents.\n",
    "\n",
    "    This tool is used to retrieve detailed information based on content similarity. It excels at answering questions requiring deeper context or extended information from original documents, making it suitable for handling more complex or background-intensive queries.\n",
    "\n",
    "    Typical use cases include:\n",
    "    1. **Content Queries**: Providing in-depth answers to questions that require extracting detailed information from original documents.\n",
    "    2. **Context Retrieval**: Handling queries that need extensive background or supporting information by matching content chunks based on similarity.\n",
    "    \"\"\"\n",
    "\n",
    "    query: str = Field(\n",
    "        description=(\n",
    "            \"A query for retrieving similar chunks of text that provide detailed context or background information to answer the user's query.\"\n",
    "        )\n",
    "    )\n",
    "\n",
    "system_instruction = \"\"\"As the Advanced Query Solver, your primary role is to assist users by breaking down complex queries into manageable subquestions and providing a clear action plan for resolving them. You are responsible for ensuring that each step of the query-solving process is methodically planned and executed, with attention to dependencies between different subquestions.\n",
    "\n",
    "When interacting with users, adhere to the following instructions:\n",
    "\n",
    "1. Query Analysis:\n",
    "- Upon receiving a user query, begin by analyzing the query to determine its structure and dependencies. \n",
    "- Create a dependency graph that outlines how each subquestion relates to others and the order in which they should be resolved.\n",
    "    - Example: If the user asks about the status of a project and its potential impact on product delivery, identify the key subquestions: \n",
    "    'What is the current status of the project?'\n",
    "    'Are there any blockers or delays affecting the timeline?'\n",
    "    'What is the estimated impact on the upcoming product release?'\n",
    "    - Ensure that subquestions dependent on the resolution of earlier steps are properly sequenced.\n",
    "\n",
    "2. Subquestion Generation:\n",
    "- Once the dependency graph is established, break down the original query into a series of subquestions. Each subquestion should be clear, concise, and directly address a portion of the user's original inquiry.\n",
    "- Ensure that all generated subquestions are relevant to solving the user’s overall query and follow the logical structure of the dependency graph.\n",
    "    - Example: If investigating a system error, break it down into:\n",
    "    'What caused the error?'\n",
    "    'Which systems are affected?'\n",
    "    'What are the potential solutions or workarounds?'\n",
    "\n",
    "3. Action Plan Generation:\n",
    "- After breaking down the query into subquestions, generate a clear action plan that specifies how to answer each subquestion and resolve the entire query.\n",
    "- The action plan should be structured sequentially, reflecting the dependencies outlined in the graph, with clear steps for retrieving or processing the information required to answer each subquestion.\n",
    "    - Example: For a product update query, the action plan might include:\n",
    "    'Step 1: Retrieve the latest project status.'\n",
    "    'Step 2: Identify any blockers or delays reported in the last week.'\n",
    "    'Step 3: Analyze how these issues might impact the product release timeline.'\n",
    "\n",
    "4. Problem Solving Execution:\n",
    "- Execute each step of the action plan sequentially, ensuring that all subquestions are answered and that dependencies between them are respected.\n",
    "- As you solve each subquestion, aggregate the results into a comprehensive response that directly addresses the user's original query.\n",
    "- Ensure that the final response provides clarity on how each part of the solution was derived and how the user can proceed with the information.\n",
    "\n",
    "5. Communication:\n",
    "- Clearly explain the steps taken to resolve the user’s query, ensuring they understand the rationale behind each subquestion and how it contributed to the final solution.\n",
    "- Confirm with the user if additional clarification is needed on any specific subquestion or action plan step.\n",
    "- Maintain a professional and supportive tone, ensuring that your responses are structured, informative, and actionable for the user’s needs.\n",
    "\n",
    "Your goal is to help users navigate complex queries by decomposing them into logical steps and providing a structured action plan for resolving them. Always prioritize accuracy, clarity, and logical flow in your interactions to ensure user satisfaction and problem resolution.\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "class ChatService:\n",
    "    def __init__(self):\n",
    "        self.tools = [\n",
    "            openai.pydantic_function_tool(GraphKnowledge),\n",
    "            openai.pydantic_function_tool(VectorChunks),\n",
    "        ]\n",
    "        self._syste_message = [{\"role\": \"system\", \"content\": system_instruction}]\n",
    "\n",
    "    def chat(\n",
    "        self, session: Session, messages: list = []\n",
    "    ) -> Generator[ChatEvent, None, None]:\n",
    "\n",
    "        if not messages or len(messages) == 0:\n",
    "            yield ChatEvent(event_type=EventType.ERROR, payload=\"No messages provided\")\n",
    "            return\n",
    "\n",
    "        # Step 1: Check if the user exists in the `users` table\n",
    "        response_messages = []\n",
    "\n",
    "        # while condition, if  response.choices[0].message.tool_calls is None, then return; otherwise loop\n",
    "        while True:\n",
    "            response = fc_llm.chat.completions.create(\n",
    "                model=\"gpt-4o\",\n",
    "                messages=(self._syste_message + messages + response_messages),\n",
    "                tools=self.tools,\n",
    "            )\n",
    "            if response.choices[0].message.tool_calls is None:\n",
    "                yield ChatEvent(\n",
    "                    event_type=EventType.FINISHED,\n",
    "                    payload={\n",
    "                        \"role\": \"assistant\",\n",
    "                        \"content\": response.choices[0].message.content,\n",
    "                    },\n",
    "                )\n",
    "                return\n",
    "\n",
    "            try:\n",
    "                tool_call = response.choices[0].message.tool_calls[0]\n",
    "                tool_call_message = response.choices[0].message.model_dump()\n",
    "                yield ChatEvent(\n",
    "                    event_type=EventType.TOOL_CALL, payload=tool_call_message\n",
    "                )\n",
    "                response_messages.append(tool_call_message)\n",
    "\n",
    "                for tool_call in response.choices[0].message.tool_calls:\n",
    "                    if tool_call.function.name == \"GraphKnowledge\":\n",
    "                        args = json.loads(tool_call.function.arguments)\n",
    "                        print(f\"call function GraphKnowledge\", args)\n",
    "                        graph_data = retrieve_knowledge_graph(args[\"query\"])\n",
    "                        tool_call_result = {\n",
    "                            \"graph_data\": graph_data\n",
    "                        }\n",
    "                    if tool_call.function.name == \"VectorChunks\":\n",
    "                        args = json.loads(tool_call.function.arguments)\n",
    "                        print(f\"call function VectorChunks\", args)\n",
    "                        graph_data = retrieve_knowledge_graph(args[\"query\"])\n",
    "                        chunks = retrieve_knowledge_embedded_chunks(args[\"query\"])\n",
    "                        tool_call_result = {\n",
    "                            \"chunks_data\": chunks\n",
    "                        }\n",
    "                    else:\n",
    "                        raise ValueError(\n",
    "                            f\"Unknown tool call and message: {response.choices[0].message.model_dump_json()}\"\n",
    "                        )\n",
    "\n",
    "                    tool_call_result_message = {\n",
    "                        \"role\": \"tool\",\n",
    "                        \"content\": json.dumps(tool_call_result),\n",
    "                        \"tool_call_id\": tool_call.id,\n",
    "                    }\n",
    "\n",
    "                    yield ChatEvent(\n",
    "                        event_type=EventType.TOOL_CALL_RESPONSE,\n",
    "                        payload=tool_call_result_message,\n",
    "                    )\n",
    "\n",
    "                    response_messages.append(tool_call_result_message)\n",
    "            except Exception as e:\n",
    "                traceback.print_exc()\n",
    "                session.rollback\n",
    "\n",
    "                yield ChatEvent(\n",
    "                    event_type=EventType.ERROR,\n",
    "                    payload=f\"An error occurred while processing the request.{e}\",\n",
    "                )\n",
    "\n",
    "\n",
    "cs = ChatService()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data: {\"content\": \"Sure, I can help with that. To provide a summary of the performance improvements of TiDB from version 6.5 to the newest version, we need to gather detailed information about the key changes and enhancements introduced in each version. Here\\u2019s how we will break down and resolve this query:\\n\\n### Query Analysis\\nWe need to determine the following:\\n1. What versions exist between 6.5 and the newest version?\\n2. What performance improvements were introduced in each intermediate and the newest version?\\n\\n### Dependency Graph\\n1. **List Versions**: Identify the versions from 6.5 to the newest version.\\n2. **Version-Specific Improvements**: For each identified version, list the performance improvements.\\n\\n### Subquestions\\n1. **Identify Versions ranging from 6.5 to the newest**\\n    - What versions of TiDB are available between 6.5 and the newest one?\\n2. **Detail Performance Improvements for Each Version**\\n    - What are the performance improvements in each of the identified versions?\\n\\n### Action Plan\\n1. **Retrieve Version List**: List the versions available between TiDB 6.5 and the newest version.\\n2. **Gather Performance Improvements**:\\n    - For each version identified in Step 1, retrieve detailed performance improvements.\\n\\n### Execution\\nLet\\u2019s start by listing the versions and then proceed to gather details on performance improvements for each.\\n\\n#### Step 1: Retrieve Version List\\n\\nI will execute a VectorChunks query to retrieve the list of versions between TiDB 6.5 and the newest version:\\n\", \"refusal\": null, \"role\": \"assistant\", \"function_call\": null, \"tool_calls\": [{\"id\": \"call_lwpuLQoFWju8KnDDsst2KkgO\", \"function\": {\"arguments\": \"{\\\"query\\\":\\\"List the TiDB versions from 6.5 to the latest version.\\\"}\", \"name\": \"VectorChunks\"}, \"type\": \"function\"}]}\n",
      "\n",
      "\n",
      "call function VectorChunks {'query': 'List the TiDB versions from 6.5 to the latest version.'}\n",
      "data: {\"role\": \"tool\", \"content\": \"{\\\"chunks_data\\\": [\\\"## 6.5\\\\n\\\\n- [6.5.10](/releases/release-6.5.10.md): 2024-06-20\\\\n- [6.5.9](/releases/release-6.5.9.md): 2024-04-12\\\\n- [6.5.8](/releases/release-6.5.8.md): 2024-02-02\\\\n- [6.5.7](/releases/release-6.5.7.md): 2024-01-08\\\\n- [6.5.6](/releases/release-6.5.6.md): 2023-12-07\\\\n- [6.5.5](/releases/release-6.5.5.md): 2023-09-21\\\\n- [6.5.4](/releases/release-6.5.4.md): 2023-08-28\\\\n- [6.5.3](/releases/release-6.5.3.md): 2023-06-14\\\\n- [6.5.2](/releases/release-6.5.2.md): 2023-04-21\\\\n- [6.5.1](/releases/release-6.5.1.md): 2023-03-10\\\\n- [6.5.0](/releases/release-6.5.0.md): 2022-12-29\\\", \\\"## 6.5\\\\n\\\\n- [6.5.10](/releases/release-6.5.10.md): 2024-06-20\\\\n- [6.5.9](/releases/release-6.5.9.md): 2024-04-12\\\\n- [6.5.8](/releases/release-6.5.8.md): 2024-02-02\\\\n- [6.5.7](/releases/release-6.5.7.md): 2024-01-08\\\\n- [6.5.6](/releases/release-6.5.6.md): 2023-12-07\\\\n- [6.5.5](/releases/release-6.5.5.md): 2023-09-21\\\\n- [6.5.4](/releases/release-6.5.4.md): 2023-08-28\\\\n- [6.5.3](/releases/release-6.5.3.md): 2023-06-14\\\\n- [6.5.2](/releases/release-6.5.2.md): 2023-04-21\\\\n- [6.5.1](/releases/release-6.5.1.md): 2023-03-10\\\\n- [6.5.0](/releases/release-6.5.0.md): 2022-12-29\\\", \\\"## 6.1\\\\n\\\\n- [6.1.7](/releases/release-6.1.7.md): 2023-07-12\\\\n- [6.1.6](/releases/release-6.1.6.md): 2023-04-12\\\\n- [6.1.5](/releases/release-6.1.5.md): 2023-02-28\\\\n- [6.1.4](/releases/release-6.1.4.md): 2023-02-08\\\\n- [6.1.3](/releases/release-6.1.3.md): 2022-12-05\\\\n- [6.1.2](/releases/release-6.1.2.md): 2022-10-24\\\\n- [6.1.1](/releases/release-6.1.1.md): 2022-09-01\\\\n- [6.1.0](/releases/release-6.1.0.md): 2022-06-13\\\", \\\"## 6.5\\\\n\\\\n- [6.5.10](/releases/release-6.5.10.md): 2024-06-20\\\\n- [6.5.9](/releases/release-6.5.9.md): 2024-04-12\\\\n- [6.5.8](/releases/release-6.5.8.md): 2024-02-02\\\\n- [6.5.7](/releases/release-6.5.7.md): 2024-01-08\\\\n- [6.5.6](/releases/release-6.5.6.md): 2023-12-07\\\\n- [6.5.5](/releases/release-6.5.5.md): 2023-09-21\\\\n- [6.5.4](/releases/release-6.5.4.md): 2023-08-28\\\\n- [6.5.3](/releases/release-6.5.3.md): 2023-06-14\\\\n- [6.5.2](/releases/release-6.5.2.md): 2023-04-21\\\\n- [6.5.1](/releases/release-6.5.1.md): 2023-03-10\\\\n- [6.5.0](/releases/release-6.5.0.md): 2022-12-29\\\", \\\"## 6.1\\\\n\\\\n- [6.1.7](/releases/release-6.1.7.md): 2023-07-12\\\\n- [6.1.6](/releases/release-6.1.6.md): 2023-04-12\\\\n- [6.1.5](/releases/release-6.1.5.md): 2023-02-28\\\\n- [6.1.4](/releases/release-6.1.4.md): 2023-02-08\\\\n- [6.1.3](/releases/release-6.1.3.md): 2022-12-05\\\\n- [6.1.2](/releases/release-6.1.2.md): 2022-10-24\\\\n- [6.1.1](/releases/release-6.1.1.md): 2022-09-01\\\\n- [6.1.0](/releases/release-6.1.0.md): 2022-06-13\\\"]}\", \"tool_call_id\": \"call_lwpuLQoFWju8KnDDsst2KkgO\"}\n",
      "\n",
      "\n",
      "data: {\"content\": \"We have identified the versions of TiDB from 6.5 to the latest available version. The versions between 6.5 and the newest include:\\n\\n1. 6.5.x series with versions:\\n    - 6.5.0\\n    - 6.5.1\\n    - 6.5.2\\n    - 6.5.3\\n    - 6.5.4\\n    - 6.5.5\\n    - 6.5.6\\n    - 6.5.7\\n    - 6.5.8\\n    - 6.5.9\\n    - 6.5.10\\n\\n### Next Steps: Detail Performance Improvements for Each Version\\nWe will now gather the performance improvements for each of these versions from the release notes.\\n\\n#### Step 2: Gather Performance Improvements\\nWe will query detailed performance improvements for each of these versions using the `VectorChunks`.\\n\\nHere is our plan for querying the performance improvements for each version.\\n\\n#### Parallel Queries for Each Version Release Notes\\nWe will run parallel queries to gather improvement details for each version.\\n\\n### Execution\\n\\nLet's proceed with these parallel queries to retrieve performance improvements for versions from 6.5.0 to 6.5.10.\", \"refusal\": null, \"role\": \"assistant\", \"function_call\": null, \"tool_calls\": [{\"id\": \"call_ii1R7zDmL6XB3eqOoBpqhebd\", \"function\": {\"arguments\": \"{\\\"query\\\": \\\"Performance improvements in TiDB 6.5.0\\\"}\", \"name\": \"VectorChunks\"}, \"type\": \"function\"}, {\"id\": \"call_EEtst10ZBC3tSxpNqI2zZ1Py\", \"function\": {\"arguments\": \"{\\\"query\\\": \\\"Performance improvements in TiDB 6.5.1\\\"}\", \"name\": \"VectorChunks\"}, \"type\": \"function\"}, {\"id\": \"call_I7ajl2W19pYhpbIODm0Ze9gI\", \"function\": {\"arguments\": \"{\\\"query\\\": \\\"Performance improvements in TiDB 6.5.2\\\"}\", \"name\": \"VectorChunks\"}, \"type\": \"function\"}, {\"id\": \"call_O7r0BDQxUGF0c7koJQADPCCP\", \"function\": {\"arguments\": \"{\\\"query\\\": \\\"Performance improvements in TiDB 6.5.3\\\"}\", \"name\": \"VectorChunks\"}, \"type\": \"function\"}, {\"id\": \"call_REy4uxdgWdGmuEbOUTHV6x1E\", \"function\": {\"arguments\": \"{\\\"query\\\": \\\"Performance improvements in TiDB 6.5.4\\\"}\", \"name\": \"VectorChunks\"}, \"type\": \"function\"}, {\"id\": \"call_xSSr4ZhQz6fajuBFtmXuksZy\", \"function\": {\"arguments\": \"{\\\"query\\\": \\\"Performance improvements in TiDB 6.5.5\\\"}\", \"name\": \"VectorChunks\"}, \"type\": \"function\"}, {\"id\": \"call_IdTh8s4HCgkj0HVKN9cQHXGx\", \"function\": {\"arguments\": \"{\\\"query\\\": \\\"Performance improvements in TiDB 6.5.6\\\"}\", \"name\": \"VectorChunks\"}, \"type\": \"function\"}, {\"id\": \"call_gKEpZXDawLKN6FMre5KCbA1R\", \"function\": {\"arguments\": \"{\\\"query\\\": \\\"Performance improvements in TiDB 6.5.7\\\"}\", \"name\": \"VectorChunks\"}, \"type\": \"function\"}, {\"id\": \"call_M1fEpmkqXH2sxTG0svRMkFli\", \"function\": {\"arguments\": \"{\\\"query\\\": \\\"Performance improvements in TiDB 6.5.8\\\"}\", \"name\": \"VectorChunks\"}, \"type\": \"function\"}, {\"id\": \"call_eIDzMTIaI4Qtylmdoo1oNF5U\", \"function\": {\"arguments\": \"{\\\"query\\\": \\\"Performance improvements in TiDB 6.5.9\\\"}\", \"name\": \"VectorChunks\"}, \"type\": \"function\"}, {\"id\": \"call_nVWn138drejMI2Vqvk1PA3Q9\", \"function\": {\"arguments\": \"{\\\"query\\\": \\\"Performance improvements in TiDB 6.5.10\\\"}\", \"name\": \"VectorChunks\"}, \"type\": \"function\"}]}\n",
      "\n",
      "\n",
      "call function VectorChunks {'query': 'Performance improvements in TiDB 6.5.0'}\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    for event in cs.chat(session, [{\n",
    "        \"role\":\"user\",\n",
    "        \"content\": \"could you summary the performance improvement of tidb from version 6.5 to newest version\"\n",
    "    }]):\n",
    "        print(f\"data: {json.dumps(event.payload)}\\n\\n\")\n",
    "except Exception as e:\n",
    "    print(f\"data: {json.dumps({'event_type': 'ERROR', 'payload': str(e)})}\\n\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
